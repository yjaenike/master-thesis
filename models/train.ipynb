{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df38f92-be7a-433e-93bd-a8c51e06e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62974dd-a418-4011-8ff0-574caa095a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities \n",
    "from options.options import is_notebook, get_options, update_options, print_options\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import sys\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_utils.ts_dataset import TSDataset\n",
    "from data_utils.data_utils import prepare_dataloaders\n",
    "import pandas as pd\n",
    "\n",
    "from preprocessor.preprocessor import PreprocessingPipeline\n",
    "\n",
    "# Training Utils\n",
    "from train_utils.train_utils import *\n",
    "import wandb\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformer\n",
    "from tstransformer.Models import Transformer\n",
    "from tstransformer.Optim import ScheduledOptim\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa37698-c874-4c10-993c-f9c657d48bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  After Empty Cache ####\n",
      "Total memory: 12288.0 MB\n",
      "Free memory:  10885.1875 MB\n",
      "Used memory:  1402.8125 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper function to determin GPU usage\n",
    "def get_gpu_memory(name = \"GPU Memory\", verbose = True):\n",
    "    import nvidia_smi\n",
    "    nvidia_smi.nvmlInit()\n",
    "\n",
    "    \n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "    \n",
    "    memory = {\"total\":  info.total / (1024 * 1024), \"free\": info.free / (1024 * 1024), \"used\": info.used / (1024 * 1024)}\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"#### \", name , \"####\")\n",
    "        print(\"Total memory:\", memory[\"total\"], \"MB\")\n",
    "        print(\"Free memory: \", memory[\"free\"], \"MB\")\n",
    "        print(\"Used memory: \", memory[\"used\"], \"MB\")\n",
    "        print(\"\")\n",
    "    \n",
    "    nvidia_smi.nvmlShutdown()\n",
    "    \n",
    "    return memory\n",
    "\n",
    "#_=get_gpu_memory(\"Before Empty Cache\")\n",
    "torch.cuda.empty_cache()\n",
    "_=get_gpu_memory(\"After Empty Cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4e8a0b-3b3d-4156-a492-9ee151888fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1m train_path \u001b[0m:  /home/yannic/master-thesis/data_air/prsa_data.parquet\n",
      "\u001b[93m\u001b[1m val_path \u001b[0m:  /home/yannic/master-thesis/data_air/prsa_data.parquet\n",
      "\u001b[93m\u001b[1m src_sequence_size \u001b[0m:  11\n",
      "\u001b[93m\u001b[1m trg_sequence_size \u001b[0m:  11\n",
      "\u001b[93m\u001b[1m src_pad_idx \u001b[0m:  0\n",
      "\u001b[93m\u001b[1m trg_pad_idx \u001b[0m:  0\n",
      "\u001b[93m\u001b[1m nsamples \u001b[0m:  0.1\n",
      "\u001b[93m\u001b[1m epoch \u001b[0m:  10\n",
      "\u001b[93m\u001b[1m batch_size \u001b[0m:  64\n",
      "\u001b[93m\u001b[1m window_size \u001b[0m:  256\n",
      "\u001b[93m\u001b[1m loss_func \u001b[0m:  rmse\n",
      "\u001b[93m\u001b[1m learning_rate \u001b[0m:  0.001\n",
      "\u001b[93m\u001b[1m d_model \u001b[0m:  512\n",
      "\u001b[93m\u001b[1m d_inner_hidden \u001b[0m:  2048\n",
      "\u001b[93m\u001b[1m d_key \u001b[0m:  512\n",
      "\u001b[93m\u001b[1m d_value \u001b[0m:  512\n",
      "\u001b[93m\u001b[1m d_sequence \u001b[0m:  512\n",
      "\u001b[93m\u001b[1m n_head \u001b[0m:  8\n",
      "\u001b[93m\u001b[1m n_layers \u001b[0m:  6\n",
      "\u001b[93m\u001b[1m lr_mul \u001b[0m:  2.0\n",
      "\u001b[93m\u001b[1m seed \u001b[0m:  False\n",
      "\u001b[93m\u001b[1m dropout \u001b[0m:  0.1\n",
      "\u001b[93m\u001b[1m embs_share_weight \u001b[0m:  False\n",
      "\u001b[93m\u001b[1m proj_share_weight \u001b[0m:  False\n",
      "\u001b[93m\u001b[1m scale_emb_or_prj \u001b[0m:  prj\n",
      "\u001b[93m\u001b[1m output_dir \u001b[0m:  ./output\n",
      "\u001b[93m\u001b[1m use_wandb \u001b[0m:  True\n",
      "\u001b[93m\u001b[1m save_mode \u001b[0m:  best\n",
      "\u001b[93m\u001b[1m cuda \u001b[0m:  True\n",
      "\u001b[93m\u001b[1m label_smoothing \u001b[0m:  True\n"
     ]
    }
   ],
   "source": [
    "opt = get_options()\n",
    "print_options(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26cdbbc-195c-4989-85a8-18f4dbb69163",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97591670-2d35-476c-923e-5618d1eb89d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Shape: (420768, 11) \n",
      "\n",
      "Preprocessed Dataset:\n",
      "Nans :  0\n",
      "Shape:  (420768, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>pm10</th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>co</th>\n",
       "      <th>o3</th>\n",
       "      <th>temperatur</th>\n",
       "      <th>pressure</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>rain</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257708</td>\n",
       "      <td>0.172894</td>\n",
       "      <td>0.479068</td>\n",
       "      <td>0.042473</td>\n",
       "      <td>0.398344</td>\n",
       "      <td>0.337877</td>\n",
       "      <td>-0.180366</td>\n",
       "      <td>-0.016343</td>\n",
       "      <td>-0.204900</td>\n",
       "      <td>1.522160</td>\n",
       "      <td>0.604078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118495</td>\n",
       "      <td>0.027765</td>\n",
       "      <td>0.392871</td>\n",
       "      <td>-0.148608</td>\n",
       "      <td>0.346235</td>\n",
       "      <td>0.405559</td>\n",
       "      <td>-0.292978</td>\n",
       "      <td>0.074749</td>\n",
       "      <td>-0.345709</td>\n",
       "      <td>1.413122</td>\n",
       "      <td>0.822465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.020333</td>\n",
       "      <td>-0.106805</td>\n",
       "      <td>0.257591</td>\n",
       "      <td>-0.331794</td>\n",
       "      <td>0.282495</td>\n",
       "      <td>0.379272</td>\n",
       "      <td>-0.396448</td>\n",
       "      <td>0.159459</td>\n",
       "      <td>-0.476346</td>\n",
       "      <td>1.301458</td>\n",
       "      <td>1.052115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.152077</td>\n",
       "      <td>-0.231010</td>\n",
       "      <td>0.190721</td>\n",
       "      <td>-0.505281</td>\n",
       "      <td>0.109226</td>\n",
       "      <td>0.223226</td>\n",
       "      <td>-0.491079</td>\n",
       "      <td>0.250003</td>\n",
       "      <td>-0.602353</td>\n",
       "      <td>1.188858</td>\n",
       "      <td>1.084803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.280683</td>\n",
       "      <td>-0.354956</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>-0.668109</td>\n",
       "      <td>0.043444</td>\n",
       "      <td>0.268340</td>\n",
       "      <td>-0.577962</td>\n",
       "      <td>0.336914</td>\n",
       "      <td>-0.715936</td>\n",
       "      <td>1.076822</td>\n",
       "      <td>1.181538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pm25      pm10       so2       no2        co        o3  temperatur  \\\n",
       "0  0.257708  0.172894  0.479068  0.042473  0.398344  0.337877   -0.180366   \n",
       "1  0.118495  0.027765  0.392871 -0.148608  0.346235  0.405559   -0.292978   \n",
       "2 -0.020333 -0.106805  0.257591 -0.331794  0.282495  0.379272   -0.396448   \n",
       "3 -0.152077 -0.231010  0.190721 -0.505281  0.109226  0.223226   -0.491079   \n",
       "4 -0.280683 -0.354956  0.116248 -0.668109  0.043444  0.268340   -0.577962   \n",
       "\n",
       "   pressure  dew_point      rain  wind_speed  \n",
       "0 -0.016343  -0.204900  1.522160    0.604078  \n",
       "1  0.074749  -0.345709  1.413122    0.822465  \n",
       "2  0.159459  -0.476346  1.301458    1.052115  \n",
       "3  0.250003  -0.602353  1.188858    1.084803  \n",
       "4  0.336914  -0.715936  1.076822    1.181538  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and preprocess it \n",
    "aq = pd.read_parquet(\"/home/yannic/master-thesis/data_air/prsa_data.parquet\")\n",
    "\n",
    "# With Stations\n",
    "#aq_prep = pd.concat([aq,pd.get_dummies(aq['station'], prefix='station',dummy_na=False)],axis=1).drop(['station'],axis=1).drop(columns=[\"wind_direction\"])\n",
    "\n",
    "# Without Stations\n",
    "aq_prepared = aq.drop(['station'],axis=1).drop(columns=[\"wind_direction\"]).iloc[:,4:]\n",
    "\n",
    "\n",
    "fill_type = 'ema_fast'           # OPTIONS: 'nan', 'median', 'locf', 'nocb', 'ema', 'ema_fast'\n",
    "clip_quantile_value = 0.99   # OPTIONS: range(0.0 , 1.0)\n",
    "\n",
    "preprocessing_pipe = PreprocessingPipeline(fill_type, clip_quantile_value)\n",
    "aq_preprocessed = preprocessing_pipe.fit_transform(aq_prepared)\n",
    "print(\"Preprocessed Shape:\",aq_preprocessed.shape,\"\\n\")\n",
    "\n",
    "aq_preprocessed = aq_preprocessed.iloc[:,:]\n",
    "print(\"Preprocessed Dataset:\")\n",
    "print(\"Nans : \",aq_preprocessed.isnull().sum().sum())\n",
    "print(\"Shape: \",aq_preprocessed.shape)\n",
    "aq_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0ca8dd-0fa4-4c0e-8b48-504d02cdd8c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataLoader and Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3ba3ef3-4ee2-4d22-9aa7-dbfabc71b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, validation_datalaoder, optimizer, device, opt):\n",
    "    \n",
    "    if opt[\"use_wandb\"]:\n",
    "        wandb.init(project=\"masters-thesis\", entity=\"yannicj\", config=opt)\n",
    "        #wandb.run.name = \"test_run\"\n",
    "        #wandb.config = opt\n",
    "\n",
    "    for epoch in range(opt[\"epoch\"]):\n",
    "        \n",
    "        # Initiate running losses for epoch\n",
    "        running_train_loss = 0\n",
    "        train_losses = []\n",
    "        running_val_loss = 0\n",
    "        val_losses = []\n",
    "        \n",
    "        \n",
    "        with tqdm(train_dataloader, unit=\"batch\", mininterval=1, leave=True) as tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            \n",
    "            # Train epoch\n",
    "            for data, target in train_dataloader:\n",
    "                tepoch.update(1)\n",
    "                \n",
    "                # Prepare data\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                decoder_input = data[:,-1,:].unsqueeze(dim=1)\n",
    "                \n",
    "                # Trainig step\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(data, decoder_input)\n",
    "\n",
    "                loss = calc_loss(pred, target, opt[\"loss_func\"])\n",
    "                running_train_loss += loss.item()\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Update progress bar\n",
    "                temp_mean_train_loss = sum(train_losses) / len(train_losses)\n",
    "                tqdm_loss = \"{:10.4f}\".format(temp_mean_train_loss)\n",
    "                tepoch.set_postfix(mean_train_loss=tqdm_loss)\n",
    "            \n",
    "            # Validate epoch\n",
    "            running_val_loss, val_losses = validate_epoch(model, validation_datalaoder, device, opt)\n",
    "            \n",
    "            # Update Progress Bar\n",
    "            mean_tain_loss = sum(train_losses) / len(train_losses)\n",
    "            mean_val_loss = sum(val_losses) / len(val_losses)\n",
    "            tqdm_train_loss = \"{:10.4f}\".format(mean_tain_loss)\n",
    "            tqdm_val_losses = \"{:10.4f}\".format(mean_val_loss)\n",
    "            \n",
    "            tepoch.set_postfix({\"loss\": tqdm_train_loss, \"val_loss\": tqdm_val_losses})\n",
    "            tepoch.close()\n",
    "            \n",
    "            if opt[\"use_wandb\"]:\n",
    "                wandb.log({\"train_loss\": mean_tain_loss, \"val_loss\": mean_val_loss})\n",
    "                wandb.watch(model)\n",
    "                \n",
    "            # save model localy\n",
    "            \n",
    "    \n",
    "    if opt[\"use_wandb\"]:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef0c0431-952f-4ebc-8e6b-b7530675cc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m#-------------------------------------#\u001b[0m\n",
      "\u001b[4m\u001b[1mTraining Settings:\u001b[0m\n",
      "- \u001b[1mdevice:\u001b[0m cuda\n",
      "- \u001b[1mtrain_size:\u001b[0m 0.7% (2932, 11)\n",
      "- \u001b[1meval_size:\u001b[0m 0.15% (644, 11)\n",
      "- \u001b[1mtest_size:\u001b[0m 0.15% (632, 11)\n",
      "- \u001b[1mloss_fn:\u001b[0m rmse\n",
      "\u001b[95m\u001b[1m#-------------------------------------#\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yannic/master-thesis/models/wandb/run-20221213_125321-zm4k19lr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yannicj/masters-thesis/runs/zm4k19lr\" target=\"_blank\">generous-capybara-19</a></strong> to <a href=\"https://wandb.ai/yannicj/masters-thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████████████████████████████████████████| 42/42 [00:16<00:00,  2.54batch/s, loss=1.3605, val_loss=1.1960]\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████| 42/42 [00:17<00:00,  2.38batch/s, loss=0.9562, val_loss=1.1185]\n",
      "Epoch 2: 100%|███████████████████████████████████████████████████████| 42/42 [00:17<00:00,  2.46batch/s, loss=0.9139, val_loss=1.1415]\n",
      "Epoch 3: 100%|███████████████████████████████████████████████████████| 42/42 [00:15<00:00,  2.69batch/s, loss=0.9169, val_loss=1.2298]\n",
      "Epoch 4: 100%|███████████████████████████████████████████████████████| 42/42 [00:17<00:00,  2.37batch/s, loss=0.9574, val_loss=1.0665]\n",
      "Epoch 5: 100%|███████████████████████████████████████████████████████| 42/42 [00:15<00:00,  2.73batch/s, loss=0.9394, val_loss=1.0295]\n",
      "Epoch 6: 100%|███████████████████████████████████████████████████████| 42/42 [00:17<00:00,  2.39batch/s, loss=0.9071, val_loss=1.0359]\n",
      "Epoch 7: 100%|███████████████████████████████████████████████████████| 42/42 [00:17<00:00,  2.46batch/s, loss=0.9002, val_loss=1.0376]\n",
      "Epoch 8: 100%|███████████████████████████████████████████████████████| 42/42 [00:15<00:00,  2.67batch/s, loss=0.8902, val_loss=1.0407]\n",
      "Epoch 9: 100%|███████████████████████████████████████████████████████| 42/42 [00:17<00:00,  2.37batch/s, loss=0.8871, val_loss=1.0496]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a954e3977484dfea994495265665fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▂▁▁▂▂▁▁▁▁</td></tr><tr><td>val_loss</td><td>▇▄▅█▂▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.8871</td></tr><tr><td>val_loss</td><td>1.04959</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">generous-capybara-19</strong>: <a href=\"https://wandb.ai/yannicj/masters-thesis/runs/zm4k19lr\" target=\"_blank\">https://wandb.ai/yannicj/masters-thesis/runs/zm4k19lr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221213_125321-zm4k19lr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the cuda devide\n",
    "device = torch.device('cuda' if opt[\"cuda\"] else 'cpu')\n",
    "\n",
    "# Load options\n",
    "opt = get_options()\n",
    "\n",
    "# create train, eval, test split\n",
    "data = aq_preprocessed[:int(np.round(opt[\"nsamples\"]*aq_preprocessed.shape[0]))]\n",
    "train_split, test_split = train_test_split(data, test_size=0.15, shuffle=False)\n",
    "train_split, eval_split = train_test_split(train_split, test_size=0.18, shuffle=False)\n",
    "\n",
    "# Training dataset, Evaluation dataset in each epoch, Testing dataset after training\n",
    "train_dataset, train_dataloader = prepare_dataloaders(train_split.values, opt[\"batch_size\"],window_size=opt[\"window_size\"], device=device)\n",
    "eval_dataset, eval_dataloader = prepare_dataloaders(eval_split.values,  opt[\"batch_size\"],window_size=opt[\"window_size\"], device=device)\n",
    "test_dataset, test_dataloader = prepare_dataloaders(test_split.values,  opt[\"batch_size\"],window_size=opt[\"window_size\"], device=device)\n",
    "\n",
    "# Define Transformer\n",
    "transformer = Transformer(\n",
    "        n_src_sequence=opt[\"src_sequence_size\"],\n",
    "        n_trg_sequence=opt[\"trg_sequence_size\"],\n",
    "        src_pad_idx=opt[\"src_pad_idx\"],\n",
    "        trg_pad_idx=opt[\"trg_pad_idx\"],\n",
    "        trg_emb_prj_weight_sharing=opt[\"proj_share_weight\"],\n",
    "        emb_src_trg_weight_sharing=opt[\"embs_share_weight\"],\n",
    "        d_k=opt[\"d_key\"],\n",
    "        d_v=opt[\"d_value\"],\n",
    "        d_model=opt[\"d_model\"],\n",
    "        d_sequence_vec=opt[\"d_sequence\"],\n",
    "        d_inner=opt[\"d_inner_hidden\"],\n",
    "        n_layers=opt[\"n_layers\"],\n",
    "        n_head=opt[\"n_head\"],\n",
    "        dropout=opt[\"dropout\"],\n",
    "        n_position=opt[\"d_sequence\"],\n",
    "        scale_emb_or_prj=opt[\"scale_emb_or_prj\"]).to(device)\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = optim.Adam(transformer.parameters(), lr= opt[\"learning_rate\"], betas=(0.9, 0.98), eps=1e-09)\n",
    "\n",
    "# print training settings\n",
    "print_training_settings(device, train_split, eval_split, test_split, opt[\"loss_func\"])\n",
    "\n",
    "# Start the training process\n",
    "train(transformer, train_dataloader, train_dataloader, optimizer, device, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1435e20-6d79-4721-a6c6-8ac0ae998661",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">clean-voice-16</strong>: <a href=\"https://wandb.ai/yannicj/masters-thesis/runs/36a3jlgf\" target=\"_blank\">https://wandb.ai/yannicj/masters-thesis/runs/36a3jlgf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221213_124048-36a3jlgf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed5b4d-cf1e-46db-b9c6-b3c7268533b8",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1904ae1-2d05-43ad-a54a-5be59e748f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.to(device)\n",
    "target = target.to(device)\n",
    "decoder_input = data[:,-1,:].unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460bc488-504a-4ef3-8dc7-3d0c8e44a863",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Old Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eedd28-4abb-4486-aad5-83478599a90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, training_data, optimizer, opt, device, smoothing):\n",
    "    ''' Epoch operation in training phase'''\n",
    "\n",
    "    model.train()\n",
    "    total_loss, n_word_total, n_word_correct = 0, 0, 0 \n",
    "\n",
    "    desc = '  - (Training)   '\n",
    "    for batch in tqdm(training_data, mininterval=2, desc=desc, leave=False):\n",
    "        \n",
    "        \n",
    "        # prepare data\n",
    "        src_seq = patch_src(batch.src, opt.src_pad_idx).to(device)\n",
    "        trg_seq, gold = map(lambda x: x.to(device), patch_trg(batch.trg, opt.trg_pad_idx))\n",
    "\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(src_seq, trg_seq)\n",
    "\n",
    "        # backward and update parameters\n",
    "        loss, n_correct, n_word = cal_performance(\n",
    "            pred, gold, opt.trg_pad_idx, smoothing=smoothing) \n",
    "        loss.backward()\n",
    "        optimizer.step_and_update_lr()\n",
    "\n",
    "        # note keeping\n",
    "        n_word_total += n_word\n",
    "        n_word_correct += n_correct\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    loss_per_word = total_loss/n_word_total\n",
    "    accuracy = n_word_correct/n_word_total\n",
    "    return loss_per_word, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794e8ab-576e-44d6-b3db-1140dc1d19da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, validation_data, device, opt):\n",
    "    ''' Epoch operation in evaluation phase '''\n",
    "\n",
    "    model.eval()\n",
    "    total_loss, n_word_total, n_word_correct = 0, 0, 0\n",
    "\n",
    "    desc = '  - (Validation) '\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validation_data, mininterval=2, desc=desc, leave=False):\n",
    "\n",
    "            # prepare data\n",
    "            src_seq = patch_src(batch.src, opt.src_pad_idx).to(device)\n",
    "            trg_seq, gold = map(lambda x: x.to(device), patch_trg(batch.trg, opt.trg_pad_idx))\n",
    "\n",
    "            # forward\n",
    "            pred = model(src_seq, trg_seq)\n",
    "            loss, n_correct, n_word = cal_performance(\n",
    "                pred, gold, opt.trg_pad_idx, smoothing=False)\n",
    "\n",
    "            # note keeping\n",
    "            n_word_total += n_word\n",
    "            n_word_correct += n_correct\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    loss_per_word = total_loss/n_word_total\n",
    "    accuracy = n_word_correct/n_word_total\n",
    "    return loss_per_word, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c03029-11e2-41e0-bcb0-58073615138c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, training_data, validation_data, optimizer, device, opt):\n",
    "    ''' Start training '''\n",
    "    \n",
    "    # Use wandb to plot curves, e.g. perplexity, accuracy, learning rate\n",
    "    # TODO: Implement this\n",
    "\n",
    "    log_train_file = os.path.join(opt[\"output_dir\"], 'train.log')\n",
    "    log_valid_file = os.path.join(opt[\"output_dir\"], 'valid.log')\n",
    "\n",
    "    print('[Info] Training performance will be written to file: {} and {}'.format(log_train_file, log_valid_file))\n",
    "\n",
    "    with open(log_train_file, 'w') as log_tf, open(log_valid_file, 'w') as log_vf:\n",
    "        log_tf.write('epoch,loss,ppl,accuracy\\n')\n",
    "        log_vf.write('epoch,loss,ppl,accuracy\\n')\n",
    "\n",
    "    def print_performances(header, accu, start_time, lr):\n",
    "        print('  - {header:12} , accuracy: {accu:3.3f} %, lr: {lr:8.5f}, ''elapse: {elapse:3.3f} min'.format(\n",
    "                  header=f\"({header})\",accu=100*accu, elapse=(time.time()-start_time)/60, lr=lr))\n",
    "\n",
    "    #valid_accus = []\n",
    "    valid_losses = []\n",
    "    for epoch_i in range(opt[\"epoch\"]):\n",
    "        print('[ Epoch', epoch_i, ']')\n",
    "\n",
    "        start = time.time()\n",
    "        train_loss, train_accu = train_epoch(\n",
    "            model, training_data, optimizer, opt, device, smoothing=opt[\"label_smoothing\"])\n",
    "        \n",
    "        \n",
    "        # Current learning rate\n",
    "        lr = optimizer._optimizer.param_groups[0]['lr']\n",
    "        print_performances('Training', train_accu, start, lr)\n",
    "\n",
    "        start = time.time()\n",
    "        valid_loss, valid_accu = eval_epoch(model, validation_data, device, opt)\n",
    "        valid_ppl = math.exp(min(valid_loss, 100))\n",
    "        print_performances('Validation', valid_ppl, valid_accu, start, lr)\n",
    "\n",
    "        valid_losses += [valid_loss]\n",
    "\n",
    "        checkpoint = {'epoch': epoch_i, 'settings': opt, 'model': model.state_dict()}\n",
    "        \n",
    "        if opt[\"save_mode\"] == 'all':\n",
    "            model_name = 'model_accu_{accu:3.3f}.chkpt'.format(accu=100*valid_accu)\n",
    "            torch.save(checkpoint, model_name)\n",
    "        elif opt[\"save_mode\"] == 'best':\n",
    "            model_name = 'model.chkpt'\n",
    "            if valid_loss <= min(valid_losses):\n",
    "                torch.save(checkpoint, os.path.join(opt[\"output_dir\"], model_name))\n",
    "                print('    - [Info] The checkpoint file has been updated.')\n",
    "\n",
    "        with open(log_train_file, 'a') as log_tf, open(log_valid_file, 'a') as log_vf:\n",
    "            log_tf.write('{epoch},{loss: 8.5f},{ppl: 8.5f},{accu:3.3f}\\n'.format(\n",
    "                epoch=epoch_i, loss=train_loss,\n",
    "                ppl=train_ppl, accu=100*train_accu))\n",
    "            log_vf.write('{epoch},{loss: 8.5f},{ppl: 8.5f},{accu:3.3f}\\n'.format(\n",
    "                epoch=epoch_i, loss=valid_loss,\n",
    "                ppl=valid_ppl, accu=100*valid_accu))\n",
    "\n",
    "        if opt[\"use_tb\"]:\n",
    "            tb_writer.add_scalars('ppl', {'train': train_ppl, 'val': valid_ppl}, epoch_i)\n",
    "            tb_writer.add_scalars('accuracy', {'train': train_accu*100, 'val': valid_accu*100}, epoch_i)\n",
    "            tb_writer.add_scalar('learning_rate', lr, epoch_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bbfdf5-aa5b-4c8d-b559-c8453355662a",
   "metadata": {
    "tags": []
   },
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be5f49-3878-4a99-9eb6-ca2cee25d16c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Testing and Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48184761-8911-44c4-9274-81ea3719711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_dataloader = prepare_dataloaders(aq_preprocessed.values, opt[\"batch_size\"],window_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b0d4b-69cc-4810-8507-64b4cd67fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "j = 0\n",
    "for data, label in train_dataloader:\n",
    "    x = data[0]\n",
    "    y = label[0]\n",
    "    if j==i:\n",
    "        break\n",
    "    j+=1\n",
    "\n",
    "x_df = pd.DataFrame(x.numpy(), columns=['pm25', 'pm10', 'so2', 'no2', 'co', 'o3', 'temperatur', 'pressure',\n",
    "       'dew_point', 'rain', 'wind_speed'])\n",
    "\n",
    "y_df = pd.DataFrame(y.numpy(), columns=['pm25', 'pm10', 'so2', 'no2', 'co', 'o3', 'temperatur', 'pressure',\n",
    "       'dew_point', 'rain', 'wind_speed'])\n",
    "\n",
    "sample = pd.concat([x_df, y_df]).reset_index().drop(columns=[\"index\"]).round(2).astype(str)\n",
    "real = aq_preprocessed[i+0:i+11].reset_index().drop(columns=[\"index\"]).round(2).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c851e-0d51-4c5f-9d02-235170c5c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ec66e-e588-4750-8e15-aa6ceecf2603",
   "metadata": {},
   "outputs": [],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ab5f3-b8f0-45f3-9766-06991c32709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sample == real).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306c0da-f69f-4824-93dc-5a6b1f128fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_dataset[3][0].numpy(), columns=['pm25', 'pm10', 'so2', 'no2', 'co', 'o3', 'temperatur', 'pressure',\n",
    "       'dew_point', 'rain', 'wind_speed']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f0c08-1251-4f42-879c-1820d924542f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-lab",
   "language": "python",
   "name": "jupyter-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
