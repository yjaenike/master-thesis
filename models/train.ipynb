{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df38f92-be7a-433e-93bd-a8c51e06e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d62974dd-a418-4011-8ff0-574caa095a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities \n",
    "from options.options import is_notebook, get_options, update_options, print_options\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datautils.ts_dataset import TSDataset\n",
    "from datautils.data import prepare_dataloaders\n",
    "import pandas as pd\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformer\n",
    "#import tstransformer.Constants as Constants\n",
    "from tstransformer.Models import Transformer\n",
    "from tstransformer.Optim import ScheduledOptim\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5e4e8a0b-3b3d-4156-a492-9ee151888fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1m           train_path \u001b[0m:  /home/yannic/master-thesis/data_air/prsa_data.parquet\n",
      "\u001b[93m\u001b[1m             val_path \u001b[0m:  /home/yannic/master-thesis/data_air/prsa_data.parquet\n",
      "\u001b[93m\u001b[1m                epoch \u001b[0m:  10\n",
      "\u001b[93m\u001b[1m           batch_size \u001b[0m:  32\n",
      "\u001b[93m\u001b[1m              d_model \u001b[0m:  512\n",
      "\u001b[93m\u001b[1m       d_inner_hidden \u001b[0m:  2048\n",
      "\u001b[93m\u001b[1m                d_key \u001b[0m:  64\n",
      "\u001b[93m\u001b[1m              d_value \u001b[0m:  64\n",
      "\u001b[93m\u001b[1m           d_sequence \u001b[0m:  512\n",
      "\u001b[93m\u001b[1m               n_head \u001b[0m:  8\n",
      "\u001b[93m\u001b[1m             n_layers \u001b[0m:  6\n",
      "\u001b[93m\u001b[1m       n_warmup_steps \u001b[0m:  4000\n",
      "\u001b[93m\u001b[1m               lr_mul \u001b[0m:  2.0\n",
      "\u001b[93m\u001b[1m                 seed \u001b[0m:  False\n",
      "\u001b[93m\u001b[1m              dropout \u001b[0m:  0.1\n",
      "\u001b[93m\u001b[1m    embs_share_weight \u001b[0m:  False\n",
      "\u001b[93m\u001b[1m    proj_share_weight \u001b[0m:  False\n",
      "\u001b[93m\u001b[1m     scale_emb_or_prj \u001b[0m:  prj\n",
      "\u001b[93m\u001b[1m           output_dir \u001b[0m:  ./output\n",
      "\u001b[93m\u001b[1m               use_tb \u001b[0m:  True\n",
      "\u001b[93m\u001b[1m            use_wandb \u001b[0m:  False\n",
      "\u001b[93m\u001b[1m            save_mode \u001b[0m:  best\n",
      "\u001b[93m\u001b[1m                 cuda \u001b[0m:  True\n",
      "\u001b[93m\u001b[1m      label_smoothing \u001b[0m:  True\n"
     ]
    }
   ],
   "source": [
    "opt = get_options()\n",
    "print_options(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5480c8c-4598-4786-ab3e-34dea99cd21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "# For reproducibility\n",
    "if opt[\"seed\"] is not None:\n",
    "    torch.manual_seed(opt[\"seed\"])\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch.set_deterministic(True)\n",
    "    np.random.seed(opt[\"seed\"])\n",
    "    random.seed(opt[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c031fb-080e-40f1-b4b4-06f7358acd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not opt[\"output_dir\"]:\n",
    "    print('No experiment result will be saved.')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d972728e-4997-46e7-a939-3e43cb44a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(opt[\"output_dir\"]):\n",
    "    os.makedirs(opt[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "42c0a9f6-e82a-4d3d-8933-6a0734aec5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# define the cuda devide\n",
    "device = torch.device('cuda' if opt[\"cuda\"] else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97591670-2d35-476c-923e-5618d1eb89d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pm10</th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>co</th>\n",
       "      <th>o3</th>\n",
       "      <th>...</th>\n",
       "      <th>station_Dingling</th>\n",
       "      <th>station_Dongsi</th>\n",
       "      <th>station_Guanyuan</th>\n",
       "      <th>station_Gucheng</th>\n",
       "      <th>station_Huairou</th>\n",
       "      <th>station_Nongzhanguan</th>\n",
       "      <th>station_Shunyi</th>\n",
       "      <th>station_Tiantan</th>\n",
       "      <th>station_Wanliu</th>\n",
       "      <th>station_Wanshouxigong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  pm25  pm10  so2  no2     co    o3  ...  \\\n",
       "0  2013      3    1     0   6.0  18.0  5.0  NaN  800.0  88.0  ...   \n",
       "1  2013      3    1     1   6.0  15.0  5.0  NaN  800.0  88.0  ...   \n",
       "2  2013      3    1     2   5.0  18.0  NaN  NaN  700.0  52.0  ...   \n",
       "3  2013      3    1     3   6.0  20.0  6.0  NaN    NaN   NaN  ...   \n",
       "4  2013      3    1     4   5.0  17.0  5.0  NaN  600.0  73.0  ...   \n",
       "\n",
       "   station_Dingling  station_Dongsi  station_Guanyuan  station_Gucheng  \\\n",
       "0                 0               0                 0                1   \n",
       "1                 0               0                 0                1   \n",
       "2                 0               0                 0                1   \n",
       "3                 0               0                 0                1   \n",
       "4                 0               0                 0                1   \n",
       "\n",
       "   station_Huairou  station_Nongzhanguan  station_Shunyi  station_Tiantan  \\\n",
       "0                0                     0               0                0   \n",
       "1                0                     0               0                0   \n",
       "2                0                     0               0                0   \n",
       "3                0                     0               0                0   \n",
       "4                0                     0               0                0   \n",
       "\n",
       "   station_Wanliu  station_Wanshouxigong  \n",
       "0               0                      0  \n",
       "1               0                      0  \n",
       "2               0                      0  \n",
       "3               0                      0  \n",
       "4               0                      0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and preprocess it \n",
    "aq = pd.read_parquet(\"/home/yannic/master-thesis/data_air/prsa_data.parquet\")\n",
    "aq_prep = pd.concat([aq,pd.get_dummies(aq['station'], prefix='station',dummy_na=False)],axis=1).drop(['station'],axis=1).drop(columns=[\"wind_direction\"])\n",
    "aq_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebdf1e-391d-4618-af0d-ee5223de8fdf",
   "metadata": {},
   "source": [
    "# DataLoader and Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460bc488-504a-4ef3-8dc7-3d0c8e44a863",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76ed9d-d382-4dd2-8f5d-36c3ad1928ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_performance(pred, gold, trg_pad_idx, smoothing=False):\n",
    "    ''' Apply label smoothing if needed '''\n",
    "\n",
    "    loss = cal_loss(pred, gold, trg_pad_idx, smoothing=smoothing)\n",
    "\n",
    "    pred = pred.max(1)[1]\n",
    "    gold = gold.contiguous().view(-1)\n",
    "    non_pad_mask = gold.ne(trg_pad_idx)\n",
    "    n_correct = pred.eq(gold).masked_select(non_pad_mask).sum().item()\n",
    "    n_word = non_pad_mask.sum().item()\n",
    "\n",
    "    return loss, n_correct, n_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1421521-3849-46d3-ba18-3a98b5205b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(pred, gold, trg_pad_idx, smoothing=False):\n",
    "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
    "\n",
    "    gold = gold.contiguous().view(-1)\n",
    "\n",
    "    if smoothing:\n",
    "        eps = 0.1\n",
    "        n_class = pred.size(1)\n",
    "\n",
    "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
    "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
    "        log_prb = F.log_softmax(pred, dim=1)\n",
    "\n",
    "        non_pad_mask = gold.ne(trg_pad_idx)\n",
    "        loss = -(one_hot * log_prb).sum(dim=1)\n",
    "        loss = loss.masked_select(non_pad_mask).sum()  # average later\n",
    "    else:\n",
    "        loss = F.cross_entropy(pred, gold, ignore_index=trg_pad_idx, reduction='sum')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff66755-edab-425d-980d-2a42faee9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_src(src, pad_idx):\n",
    "    src = src.transpose(0, 1)\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648e39d-e536-44dd-972b-d8a533ae7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_trg(trg, pad_idx):\n",
    "    trg = trg.transpose(0, 1)\n",
    "    trg, gold = trg[:, :-1], trg[:, 1:].contiguous().view(-1)\n",
    "    return trg, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eedd28-4abb-4486-aad5-83478599a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, training_data, optimizer, opt, device, smoothing):\n",
    "    ''' Epoch operation in training phase'''\n",
    "\n",
    "    model.train()\n",
    "    total_loss, n_word_total, n_word_correct = 0, 0, 0 \n",
    "\n",
    "    desc = '  - (Training)   '\n",
    "    for batch in tqdm(training_data, mininterval=2, desc=desc, leave=False):\n",
    "        \n",
    "        \n",
    "        # prepare data\n",
    "        src_seq = patch_src(batch.src, opt.src_pad_idx).to(device)\n",
    "        trg_seq, gold = map(lambda x: x.to(device), patch_trg(batch.trg, opt.trg_pad_idx))\n",
    "\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(src_seq, trg_seq)\n",
    "\n",
    "        # backward and update parameters\n",
    "        loss, n_correct, n_word = cal_performance(\n",
    "            pred, gold, opt.trg_pad_idx, smoothing=smoothing) \n",
    "        loss.backward()\n",
    "        optimizer.step_and_update_lr()\n",
    "\n",
    "        # note keeping\n",
    "        n_word_total += n_word\n",
    "        n_word_correct += n_correct\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    loss_per_word = total_loss/n_word_total\n",
    "    accuracy = n_word_correct/n_word_total\n",
    "    return loss_per_word, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794e8ab-576e-44d6-b3db-1140dc1d19da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, validation_data, device, opt):\n",
    "    ''' Epoch operation in evaluation phase '''\n",
    "\n",
    "    model.eval()\n",
    "    total_loss, n_word_total, n_word_correct = 0, 0, 0\n",
    "\n",
    "    desc = '  - (Validation) '\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validation_data, mininterval=2, desc=desc, leave=False):\n",
    "\n",
    "            # prepare data\n",
    "            src_seq = patch_src(batch.src, opt.src_pad_idx).to(device)\n",
    "            trg_seq, gold = map(lambda x: x.to(device), patch_trg(batch.trg, opt.trg_pad_idx))\n",
    "\n",
    "            # forward\n",
    "            pred = model(src_seq, trg_seq)\n",
    "            loss, n_correct, n_word = cal_performance(\n",
    "                pred, gold, opt.trg_pad_idx, smoothing=False)\n",
    "\n",
    "            # note keeping\n",
    "            n_word_total += n_word\n",
    "            n_word_correct += n_correct\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    loss_per_word = total_loss/n_word_total\n",
    "    accuracy = n_word_correct/n_word_total\n",
    "    return loss_per_word, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c03029-11e2-41e0-bcb0-58073615138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_data, validation_data, optimizer, device, opt):\n",
    "    ''' Start training '''\n",
    "    \n",
    "    # Use wandb to plot curves, e.g. perplexity, accuracy, learning rate\n",
    "    # TODO: Implement this\n",
    "\n",
    "    log_train_file = os.path.join(opt[\"output_dir\"], 'train.log')\n",
    "    log_valid_file = os.path.join(opt[\"output_dir\"], 'valid.log')\n",
    "\n",
    "    print('[Info] Training performance will be written to file: {} and {}'.format(log_train_file, log_valid_file))\n",
    "\n",
    "    with open(log_train_file, 'w') as log_tf, open(log_valid_file, 'w') as log_vf:\n",
    "        log_tf.write('epoch,loss,ppl,accuracy\\n')\n",
    "        log_vf.write('epoch,loss,ppl,accuracy\\n')\n",
    "\n",
    "    def print_performances(header, accu, start_time, lr):\n",
    "        print('  - {header:12} , accuracy: {accu:3.3f} %, lr: {lr:8.5f}, ''elapse: {elapse:3.3f} min'.format(\n",
    "                  header=f\"({header})\",accu=100*accu, elapse=(time.time()-start_time)/60, lr=lr))\n",
    "\n",
    "    #valid_accus = []\n",
    "    valid_losses = []\n",
    "    for epoch_i in range(opt[\"epoch\"]):\n",
    "        print('[ Epoch', epoch_i, ']')\n",
    "\n",
    "        start = time.time()\n",
    "        train_loss, train_accu = train_epoch(\n",
    "            model, training_data, optimizer, opt, device, smoothing=opt[\"label_smoothing\"])\n",
    "        \n",
    "        \n",
    "        # Current learning rate\n",
    "        lr = optimizer._optimizer.param_groups[0]['lr']\n",
    "        print_performances('Training', train_accu, start, lr)\n",
    "\n",
    "        start = time.time()\n",
    "        valid_loss, valid_accu = eval_epoch(model, validation_data, device, opt)\n",
    "        valid_ppl = math.exp(min(valid_loss, 100))\n",
    "        print_performances('Validation', valid_ppl, valid_accu, start, lr)\n",
    "\n",
    "        valid_losses += [valid_loss]\n",
    "\n",
    "        checkpoint = {'epoch': epoch_i, 'settings': opt, 'model': model.state_dict()}\n",
    "        \n",
    "        if opt[\"save_mode\"] == 'all':\n",
    "            model_name = 'model_accu_{accu:3.3f}.chkpt'.format(accu=100*valid_accu)\n",
    "            torch.save(checkpoint, model_name)\n",
    "        elif opt[\"save_mode\"] == 'best':\n",
    "            model_name = 'model.chkpt'\n",
    "            if valid_loss <= min(valid_losses):\n",
    "                torch.save(checkpoint, os.path.join(opt[\"output_dir\"], model_name))\n",
    "                print('    - [Info] The checkpoint file has been updated.')\n",
    "\n",
    "        with open(log_train_file, 'a') as log_tf, open(log_valid_file, 'a') as log_vf:\n",
    "            log_tf.write('{epoch},{loss: 8.5f},{ppl: 8.5f},{accu:3.3f}\\n'.format(\n",
    "                epoch=epoch_i, loss=train_loss,\n",
    "                ppl=train_ppl, accu=100*train_accu))\n",
    "            log_vf.write('{epoch},{loss: 8.5f},{ppl: 8.5f},{accu:3.3f}\\n'.format(\n",
    "                epoch=epoch_i, loss=valid_loss,\n",
    "                ppl=valid_ppl, accu=100*valid_accu))\n",
    "\n",
    "        if opt[\"use_tb\"]:\n",
    "            tb_writer.add_scalars('ppl', {'train': train_ppl, 'val': valid_ppl}, epoch_i)\n",
    "            tb_writer.add_scalars('accuracy', {'train': train_accu*100, 'val': valid_accu*100}, epoch_i)\n",
    "            tb_writer.add_scalar('learning_rate', lr, epoch_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bbfdf5-aa5b-4c8d-b559-c8453355662a",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f28272-6f76-4a55-872a-502a30937d06",
   "metadata": {},
   "source": [
    "# New Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f9dd590c-78b5-420b-a2c2-98c64117ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, optimizer, opt, device):\n",
    "    \n",
    "    # Set the model into training mode\n",
    "    model.train()\n",
    "    \n",
    "    desc = '  - (Training)   '\n",
    "    for data, labels in tqdm(train_dataloader, mininterval=2, desc=desc, leave=False):\n",
    "        \n",
    "        #TODO: prepare data\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #TODO: forward pass\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data, labels)\n",
    "        \n",
    "        \n",
    "        #TODO: backward pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "59fd4c20-8672-4ee9-bcb7-cd09474fc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, validation_data, optimizer, device, opt):\n",
    "    \n",
    "    # TODO: Implement wandb connection\n",
    "    \n",
    "    # TODO: Implement logging\n",
    "    \n",
    "    def print_performance(header, accu, start_time, lr):\n",
    "        print('  - {header:12} , accuracy: {accu:3.3f} %, lr: {lr:8.5f}, elapse: {elapse:3.3f} min'.format(\n",
    "                  header=f\"({header})\",accu=100*accu, elapse=(time.time()-start_time)/60, lr=lr))\n",
    "    \n",
    "    # TODO: Training Epoch Loop\n",
    "    for epoch_i in range(opt[\"epoch\"]):\n",
    "        print(\"[Epoch: {:>3}]\".format(epoch_i))\n",
    "        \n",
    "        #TODO: write function: train_epoch() \n",
    "        train_epoch(model,train_dataloader,optimizer,opt,device)\n",
    "        \n",
    "        \n",
    "        #TODO: write function: eval_epoch() \n",
    "        #eval_epoch()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5f51464e-7320-4e4b-855e-81f98c06bde3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:   0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                   \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [150]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m update_options(opt)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [133]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, validation_data, optimizer, device, opt)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch: \u001b[39m\u001b[38;5;132;01m{:>3}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch_i))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#TODO: write function: train_epoch() \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [132]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_dataloader, optimizer, opt, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#TODO: forward pass\u001b[39;00m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/master-thesis/models/tstransformer/Models.py:338\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src_seq, trg_seq)\u001b[0m\n\u001b[1;32m    335\u001b[0m trg_mask \u001b[38;5;241m=\u001b[39m get_pad_mask(trg_seq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrg_pad_idx) \u001b[38;5;241m&\u001b[39m get_subsequent_mask(trg_seq)\n\u001b[1;32m    337\u001b[0m enc_output, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src_seq, src_mask)\n\u001b[0;32m--> 338\u001b[0m dec_output, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrg_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m seq_logit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrg_sequence_prj(dec_output)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_prj:\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/master-thesis/models/tstransformer/Models.py:214\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, trg_seq, trg_mask, enc_output, src_mask, return_attns)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_emb:\n\u001b[1;32m    213\u001b[0m     dec_output \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m--> 214\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_enc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_output\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    215\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(dec_output)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dec_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_stack:\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/master-thesis/models/tstransformer/Models.py:59\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\" Adds the positional encoding to the input vector x \"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "update_options(opt)\n",
    "train(transformer,train_dataloader,train_dataloader,optimizer,device,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13d19526-d162-49b8-a86a-dd4efb1ac6c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:         torch.Size([32, 10, 27])\n",
      "Layer shape:  torch.Size([512, 27])\n",
      "Output:       torch.Size([32, 10, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "linear_layer = nn.Linear(27, 512)\n",
    "\n",
    "desc = '  - (Training)   '\n",
    "for data, labels in tqdm(train_dataloader, mininterval=2, desc=\"Training: \", leave=False):\n",
    "    \n",
    "    print(\"Data:        \",data.shape)\n",
    "    print(\"Layer shape: \",linear_layer.weight.size())\n",
    "    output = linear_layer(data)\n",
    "    print(\"Output:      \",output.shape)\n",
    "    \n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "98094d8a-291d-48e2-a974-8eb056603810",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1562746/3941019311.py\", line 13, in <cell line: 5>\n",
      "    pred = transformer(data, labels)\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/yannic/master-thesis/models/tstransformer/Models.py\", line 338, in forward\n",
      "    enc_output, *_ = self.encoder(src_seq, src_mask)\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/yannic/master-thesis/models/tstransformer/Models.py\", line 139, in forward\n",
      "    enc_output, enc_slf_attn = enc_layer(enc_output, slf_attn_mask=src_mask)\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/yannic/master-thesis/models/tstransformer/Layers.py\", line 45, in forward\n",
      "    enc_output, enc_slf_attn = self.slf_attn(enc_input, enc_input, enc_input, mask=slf_attn_mask)\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/yannic/master-thesis/models/tstransformer/SubLayers.py\", line 95, in forward\n",
      "    q, attn = self.attention(q, k, v, mask=mask)\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/yannic/master-thesis/models/tstransformer/SubLayers.py\", line 196, in forward\n",
      "    attn = attn.masked_fill(mask == 0, -1e9)\n",
      "RuntimeError: The size of tensor a (27) must match the size of tensor b (10) at non-singleton dimension 4\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 1982, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/yannic/anaconda3/envs/jupyter-lab/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Use the defined transformer\n",
    "\n",
    "transformer.train()\n",
    "desc = '  - (Training)   '\n",
    "for data, labels in tqdm(train_dataloader, mininterval=2, desc=\"Training: \", leave=False):\n",
    "        \n",
    "    #TODO: prepare data\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    #TODO: forward pass\n",
    "    #optimizer.zero_grad()\n",
    "    pred = transformer(data, labels)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0ca8dd-0fa4-4c0e-8b48-504d02cdd8c1",
   "metadata": {},
   "source": [
    "# DataLoader and Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ef0c0431-952f-4ebc-8e6b-b7530675cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_split, test_split = train_test_split(aq_prep, test_size=0.10)\n",
    "\n",
    "train_dataset, train_dataloader = prepare_dataloaders(train_split.values, opt[\"batch_size\"],window_size=10)\n",
    "test_dataset, test_dataloader = prepare_dataloaders(test_split.values,  opt[\"batch_size\"],window_size=10)\n",
    "\n",
    "opt[\"src_sequence_size\"] = 27\n",
    "opt[\"trg_sequence_size\"] = 27\n",
    "opt[\"src_pad_idx\"] = 0\n",
    "opt[\"trg_pad_idx\"] = 0\n",
    "\n",
    "# Define Transformer\n",
    "transformer = Transformer(\n",
    "        opt[\"src_sequence_size\"],\n",
    "        opt[\"trg_sequence_size\"],\n",
    "        src_pad_idx=opt[\"src_pad_idx\"],\n",
    "        trg_pad_idx=opt[\"trg_pad_idx\"],\n",
    "        trg_emb_prj_weight_sharing=opt[\"proj_share_weight\"],\n",
    "        emb_src_trg_weight_sharing=opt[\"embs_share_weight\"],\n",
    "        d_k=opt[\"d_key\"],\n",
    "        d_v=opt[\"d_value\"],\n",
    "        d_model=opt[\"d_model\"],\n",
    "        d_sequence_vec=opt[\"d_sequence\"],\n",
    "        d_inner=opt[\"d_inner_hidden\"],\n",
    "        n_layers=opt[\"n_layers\"],\n",
    "        n_head=opt[\"n_head\"],\n",
    "        dropout=opt[\"dropout\"],\n",
    "        n_position=opt[\"d_sequence\"],\n",
    "        scale_emb_or_prj=opt[\"scale_emb_or_prj\"]).to(device)\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = ScheduledOptim(\n",
    "                optim.Adam(transformer.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
    "                opt[\"lr_mul\"], opt[\"d_model\"], opt[\"n_warmup_steps\"])\n",
    "\n",
    "# Start the training process\n",
    "# train(transformer, train_dataloader, train_dataloader, optimizer, device, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a6b36796-543c-4a0c-9936-8c247dbcc6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (linear_emb): Linear(in_features=27, out_features=512, bias=True)\n",
       "    (position_enc): PositionalEncoding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layer_stack): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (linear_emb): Linear(in_features=27, out_features=512, bias=True)\n",
       "    (position_enc): PositionalEncoding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layer_stack): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (trg_sequence_prj): Linear(in_features=512, out_features=27, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c35518-985d-47ee-9f5a-ddd66f43a20d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-lab",
   "language": "python",
   "name": "jupyter-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
