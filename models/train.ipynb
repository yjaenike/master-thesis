{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0df38f92-be7a-433e-93bd-a8c51e06e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62974dd-a418-4011-8ff0-574caa095a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities \n",
    "from options.options import is_notebook, get_options, update_options, print_options\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datautils.ts_dataset import TSDataset\n",
    "from datautils.data import prepare_dataloaders\n",
    "import pandas as pd\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformer\n",
    "import transformer.Constants as Constants\n",
    "from transformer.Models import Transformer\n",
    "from transformer.Optim import ScheduledOptim\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4e8a0b-3b3d-4156-a492-9ee151888fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1m           train_path \u001b[0m:  /home/yannic/master-thesis/data_air/prsa_data.parquet\n",
      "\u001b[93m\u001b[1m             val_path \u001b[0m:  /home/yannic/master-thesis/data_air/prsa_data.parquet\n",
      "\u001b[93m\u001b[1m                epoch \u001b[0m:  10\n",
      "\u001b[93m\u001b[1m           batch_size \u001b[0m:  32\n",
      "\u001b[93m\u001b[1m              d_model \u001b[0m:  512\n",
      "\u001b[93m\u001b[1m       d_inner_hidden \u001b[0m:  2048\n",
      "\u001b[93m\u001b[1m                d_key \u001b[0m:  64\n",
      "\u001b[93m\u001b[1m              d_value \u001b[0m:  64\n",
      "\u001b[93m\u001b[1m           d_sequence \u001b[0m:  512\n",
      "\u001b[93m\u001b[1m               n_head \u001b[0m:  8\n",
      "\u001b[93m\u001b[1m             n_layers \u001b[0m:  6\n",
      "\u001b[93m\u001b[1m       n_warmup_steps \u001b[0m:  4000\n",
      "\u001b[93m\u001b[1m               lr_mul \u001b[0m:  2.0\n",
      "\u001b[93m\u001b[1m                 seed \u001b[0m:  False\n",
      "\u001b[93m\u001b[1m              dropout \u001b[0m:  0.1\n",
      "\u001b[93m\u001b[1m    embs_share_weight \u001b[0m:  True\n",
      "\u001b[93m\u001b[1m    proj_share_weight \u001b[0m:  True\n",
      "\u001b[93m\u001b[1m     scale_emb_or_prj \u001b[0m:  prj\n",
      "\u001b[93m\u001b[1m           output_dir \u001b[0m:  ./output\n",
      "\u001b[93m\u001b[1m               use_tb \u001b[0m:  True\n",
      "\u001b[93m\u001b[1m            save_mode \u001b[0m:  best\n",
      "\u001b[93m\u001b[1m                 cuda \u001b[0m:  True\n",
      "\u001b[93m\u001b[1m      label_smoothing \u001b[0m:  True\n"
     ]
    }
   ],
   "source": [
    "opt = get_options()\n",
    "print_options(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5480c8c-4598-4786-ab3e-34dea99cd21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "# For reproducibility\n",
    "if opt[\"seed\"] is not None:\n",
    "    torch.manual_seed(opt[\"seed\"])\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch.set_deterministic(True)\n",
    "    np.random.seed(opt[\"seed\"])\n",
    "    random.seed(opt[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c031fb-080e-40f1-b4b4-06f7358acd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not opt[\"output_dir\"]:\n",
    "    print('No experiment result will be saved.')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d972728e-4997-46e7-a939-3e43cb44a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(opt[\"output_dir\"]):\n",
    "    os.makedirs(opt[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c0a9f6-e82a-4d3d-8933-6a0734aec5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cuda devide\n",
    "device = torch.device('cuda' if opt[\"cuda\"] else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97591670-2d35-476c-923e-5618d1eb89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and preprocess it \n",
    "aq = pd.read_parquet(\"/home/yannic/master-thesis/data_air/prsa_data.parquet\")\n",
    "aq_prep = pd.concat([aq,pd.get_dummies(aq['station'], prefix='station',dummy_na=False)],axis=1).drop(['station'],axis=1).drop(columns=[\"wind_direction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460bc488-504a-4ef3-8dc7-3d0c8e44a863",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c03029-11e2-41e0-bcb0-58073615138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_data, validation_data, optimizer, device, opt):\n",
    "    ''' Start training '''\n",
    "\n",
    "    # Use tensorboard to plot curves, e.g. perplexity, accuracy, learning rate\n",
    "    if opt.use_tb:\n",
    "        print(\"[Info] Use Tensorboard\")\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        tb_writer = SummaryWriter(log_dir=os.path.join(opt.output_dir, 'tensorboard'))\n",
    "\n",
    "    log_train_file = os.path.join(opt.output_dir, 'train.log')\n",
    "    log_valid_file = os.path.join(opt.output_dir, 'valid.log')\n",
    "\n",
    "    print('[Info] Training performance will be written to file: {} and {}'.format(\n",
    "        log_train_file, log_valid_file))\n",
    "\n",
    "    with open(log_train_file, 'w') as log_tf, open(log_valid_file, 'w') as log_vf:\n",
    "        log_tf.write('epoch,loss,ppl,accuracy\\n')\n",
    "        log_vf.write('epoch,loss,ppl,accuracy\\n')\n",
    "\n",
    "    def print_performances(header, ppl, accu, start_time, lr):\n",
    "        print('  - {header:12} ppl: {ppl: 8.5f}, accuracy: {accu:3.3f} %, lr: {lr:8.5f}, '\\\n",
    "              'elapse: {elapse:3.3f} min'.format(\n",
    "                  header=f\"({header})\", ppl=ppl,\n",
    "                  accu=100*accu, elapse=(time.time()-start_time)/60, lr=lr))\n",
    "\n",
    "    #valid_accus = []\n",
    "    valid_losses = []\n",
    "    for epoch_i in range(opt.epoch):\n",
    "        print('[ Epoch', epoch_i, ']')\n",
    "\n",
    "        start = time.time()\n",
    "        train_loss, train_accu = train_epoch(\n",
    "            model, training_data, optimizer, opt, device, smoothing=opt.label_smoothing)\n",
    "        train_ppl = math.exp(min(train_loss, 100))\n",
    "        # Current learning rate\n",
    "        lr = optimizer._optimizer.param_groups[0]['lr']\n",
    "        print_performances('Training', train_ppl, train_accu, start, lr)\n",
    "\n",
    "        start = time.time()\n",
    "        valid_loss, valid_accu = eval_epoch(model, validation_data, device, opt)\n",
    "        valid_ppl = math.exp(min(valid_loss, 100))\n",
    "        print_performances('Validation', valid_ppl, valid_accu, start, lr)\n",
    "\n",
    "        valid_losses += [valid_loss]\n",
    "\n",
    "        checkpoint = {'epoch': epoch_i, 'settings': opt, 'model': model.state_dict()}\n",
    "\n",
    "        if opt.save_mode == 'all':\n",
    "            model_name = 'model_accu_{accu:3.3f}.chkpt'.format(accu=100*valid_accu)\n",
    "            torch.save(checkpoint, model_name)\n",
    "        elif opt.save_mode == 'best':\n",
    "            model_name = 'model.chkpt'\n",
    "            if valid_loss <= min(valid_losses):\n",
    "                torch.save(checkpoint, os.path.join(opt.output_dir, model_name))\n",
    "                print('    - [Info] The checkpoint file has been updated.')\n",
    "\n",
    "        with open(log_train_file, 'a') as log_tf, open(log_valid_file, 'a') as log_vf:\n",
    "            log_tf.write('{epoch},{loss: 8.5f},{ppl: 8.5f},{accu:3.3f}\\n'.format(\n",
    "                epoch=epoch_i, loss=train_loss,\n",
    "                ppl=train_ppl, accu=100*train_accu))\n",
    "            log_vf.write('{epoch},{loss: 8.5f},{ppl: 8.5f},{accu:3.3f}\\n'.format(\n",
    "                epoch=epoch_i, loss=valid_loss,\n",
    "                ppl=valid_ppl, accu=100*valid_accu))\n",
    "\n",
    "        if opt.use_tb:\n",
    "            tb_writer.add_scalars('ppl', {'train': train_ppl, 'val': valid_ppl}, epoch_i)\n",
    "            tb_writer.add_scalars('accuracy', {'train': train_accu*100, 'val': valid_accu*100}, epoch_i)\n",
    "            tb_writer.add_scalar('learning_rate', lr, epoch_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0ca8dd-0fa4-4c0e-8b48-504d02cdd8c1",
   "metadata": {},
   "source": [
    "# DataLoader and Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef0c0431-952f-4ebc-8e6b-b7530675cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train, test = train_test_split(aq_prep, test_size=0.10)\n",
    "\n",
    "train_dataset, train_dataloader = prepare_dataloaders(train.values, opt[\"batch_size\"])\n",
    "test_dataset, test_dataloader = prepare_dataloaders(test.values,  opt[\"batch_size\"])\n",
    "\n",
    "opt[\"src_sequence_size\"] = 200\n",
    "opt[\"trg_sequence_size\"] = 200\n",
    "opt[\"src_pad_idx\"] = 0\n",
    "opt[\"trg_pad_idx\"] = 0\n",
    "\n",
    "# Define Transformer\n",
    "transformer = Transformer(\n",
    "        opt[\"src_sequence_size\"],\n",
    "        opt[\"trg_sequence_size\"],\n",
    "        src_pad_idx=opt[\"src_pad_idx\"],\n",
    "        trg_pad_idx=opt[\"trg_pad_idx\"],\n",
    "        trg_emb_prj_weight_sharing=opt[\"proj_share_weight\"],\n",
    "        emb_src_trg_weight_sharing=opt[\"embs_share_weight\"],\n",
    "        d_k=opt[\"d_key\"],\n",
    "        d_v=opt[\"d_value\"],\n",
    "        d_model=opt[\"d_model\"],\n",
    "        d_word_vec=opt[\"d_sequence\"],\n",
    "        d_inner=opt[\"d_inner_hidden\"],\n",
    "        n_layers=opt[\"n_layers\"],\n",
    "        n_head=opt[\"n_head\"],\n",
    "        dropout=opt[\"dropout\"],\n",
    "        scale_emb_or_prj=opt[\"scale_emb_or_prj\"]).to(device)\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = ScheduledOptim(\n",
    "                optim.Adam(transformer.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
    "                opt[\"lr_mul\"], opt[\"d_model\"], opt[\"n_warmup_steps\"])\n",
    "\n",
    "# Start the training process\n",
    "#train(transformer, training_data, validation_data, optimizer, device, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-lab",
   "language": "python",
   "name": "jupyter-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
